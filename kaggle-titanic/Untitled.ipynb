{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import pandas \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict\n",
    "import time\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import dataset \n",
    "\n",
    "train=pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop('Ticket', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop('Name', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(train['Sex'])\n",
    "train[\"Sex\"] = y_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop('Cabin', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.get_dummies(train.Embarked)\n",
    "train.drop(\"Embarked\", axis=1, inplace=True)\n",
    "train = pd.concat([train,a],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train.drop(train.columns[1], axis=1), train['Survived'], test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import random forest\n",
    "from  sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 11 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Sex            891 non-null int64\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Fare           891 non-null float64\n",
      "C              891 non-null uint8\n",
      "Q              891 non-null uint8\n",
      "S              891 non-null uint8\n",
      "dtypes: float64(2), int64(6), uint8(3)\n",
      "memory usage: 58.4 KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import KNN imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[22.   38.   26.   35.   35.     nan 54.    2.   27.   14.    4.   58.\n 20.   39.   14.   55.    2.     nan 31.     nan 35.   34.   15.   28.\n  8.   38.     nan 19.     nan   nan 40.     nan   nan 66.   28.   42.\n   nan 21.   18.   14.   40.   27.     nan  3.   19.     nan   nan   nan\n   nan 18.    7.   21.   49.   29.   65.     nan 21.   28.5   5.   11.\n 22.   38.   45.    4.     nan   nan 29.   19.   17.   26.   32.   16.\n 21.   26.   32.   25.     nan   nan  0.83 30.   22.   29.     nan 28.\n 17.   33.   16.     nan 23.   24.   29.   20.   46.   26.   59.     nan\n 71.   23.   34.   34.   28.     nan 21.   33.   37.   28.   21.     nan\n 38.     nan 47.   14.5  22.   20.   17.   21.   70.5  29.   24.    2.\n 21.     nan 32.5  32.5  54.   12.     nan 24.     nan 45.   33.   20.\n 47.   29.   25.   23.   19.   37.   16.   24.     nan 22.   24.   19.\n 18.   19.   27.    9.   36.5  42.   51.   22.   55.5  40.5    nan 51.\n 16.   30.     nan   nan 44.   40.   26.   17.    1.    9.     nan 45.\n   nan 28.   61.    4.    1.   21.   56.   18.     nan 50.   30.   36.\n   nan   nan  9.    1.    4.     nan   nan 45.   40.   36.   32.   19.\n 19.    3.   44.   58.     nan 42.     nan 24.   28.     nan 34.   45.5\n 18.    2.   32.   26.   16.   40.   24.   35.   22.   30.     nan 31.\n 27.   42.   32.   30.   16.   27.   51.     nan 38.   22.   19.   20.5\n 18.     nan 35.   29.   59.    5.   24.     nan 44.    8.   19.   33.\n   nan   nan 29.   22.   30.   44.   25.   24.   37.   54.     nan 29.\n 62.   30.   41.   29.     nan 30.   35.   50.     nan  3.   52.   40.\n   nan 36.   16.   25.   58.   35.     nan 25.   41.   37.     nan 63.\n 45.     nan  7.   35.   65.   28.   16.   19.     nan 33.   30.   22.\n 42.   22.   26.   19.   36.   24.   24.     nan 23.5   2.     nan 50.\n   nan   nan 19.     nan   nan  0.92   nan 17.   30.   30.   24.   18.\n 26.   28.   43.   26.   24.   54.   31.   40.   22.   27.   30.   22.\n   nan 36.   61.   36.   31.   16.     nan 45.5  38.   16.     nan   nan\n 29.   41.   45.   45.    2.   24.   28.   25.   36.   24.   40.     nan\n  3.   42.   23.     nan 15.   25.     nan 28.   22.   38.     nan   nan\n 40.   29.   45.   35.     nan 30.   60.     nan   nan 24.   25.   18.\n 19.   22.    3.     nan 22.   27.   20.   19.   42.    1.   32.   35.\n   nan 18.    1.   36.     nan 17.   36.   21.   28.   23.   24.   22.\n 31.   46.   23.   28.   39.   26.   21.   28.   20.   34.   51.    3.\n 21.     nan   nan   nan 33.     nan 44.     nan 34.   18.   30.   10.\n   nan 21.   29.   28.   18.     nan 28.   19.     nan 32.   28.     nan\n 42.   17.   50.   14.   21.   24.   64.   31.   45.   20.   25.   28.\n   nan  4.   13.   34.    5.   52.   36.     nan 30.   49.     nan 29.\n 65.     nan 50.     nan 48.   34.   47.   48.     nan 38.     nan 56.\n   nan  0.75   nan 38.   33.   23.   22.     nan 34.   29.   22.    2.\n  9.     nan 50.   63.   25.     nan 35.   58.   30.    9.     nan 21.\n 55.   71.   21.     nan 54.     nan 25.   24.   17.   21.     nan 37.\n 16.   18.   33.     nan 28.   26.   29.     nan 36.   54.   24.   47.\n 34.     nan 36.   32.   30.   22.     nan 44.     nan 40.5  50.     nan\n 39.   23.    2.     nan 17.     nan 30.    7.   45.   30.     nan 22.\n 36.    9.   11.   32.   50.   64.   19.     nan 33.    8.   17.   27.\n   nan 22.   22.   62.   48.     nan 39.   36.     nan 40.   28.     nan\n   nan 24.   19.   29.     nan 32.   62.   53.   36.     nan 16.   19.\n 34.   39.     nan 32.   25.   39.   54.   36.     nan 18.   47.   60.\n 22.     nan 35.   52.   47.     nan 37.   36.     nan 49.     nan 49.\n 24.     nan   nan 44.   35.   36.   30.   27.   22.   40.   39.     nan\n   nan   nan 35.   24.   34.   26.    4.   26.   27.   42.   20.   21.\n 21.   61.   57.   21.   26.     nan 80.   51.   32.     nan  9.   28.\n 32.   31.   41.     nan 20.   24.    2.     nan  0.75 48.   19.   56.\n   nan 23.     nan 18.   21.     nan 18.   24.     nan 32.   23.   58.\n 50.   40.   47.   36.   20.   32.   25.     nan 43.     nan 40.   31.\n 70.   31.     nan 18.   24.5  18.   43.   36.     nan 27.   20.   14.\n 60.   25.   14.   19.   18.   15.   31.    4.     nan 25.   60.   52.\n 44.     nan 49.   42.   18.   35.   18.   25.   26.   39.   45.   42.\n 22.     nan 24.     nan 48.   29.   52.   19.   38.   27.     nan 33.\n  6.   17.   34.   50.   27.   20.   30.     nan 25.   25.   29.   11.\n   nan 23.   23.   28.5  48.   35.     nan   nan   nan 36.   21.   24.\n 31.   70.   16.   30.   19.   31.    4.    6.   33.   23.   48.    0.67\n 28.   18.   34.   33.     nan 41.   20.   36.   16.   51.     nan 30.5\n   nan 32.   24.   48.   57.     nan 54.   18.     nan  5.     nan 43.\n 13.   17.   29.     nan 25.   25.   18.    8.    1.   46.     nan 16.\n   nan   nan 25.   39.   49.   31.   30.   30.   34.   31.   11.    0.42\n 27.   31.   39.   18.   39.   33.   26.   39.   35.    6.   30.5    nan\n 23.   31.   43.   10.   52.   27.   38.   27.    2.     nan   nan  1.\n   nan 62.   15.    0.83   nan 23.   18.   39.   21.     nan 32.     nan\n 20.   16.   30.   34.5  17.   42.     nan 35.   28.     nan  4.   74.\n  9.   16.   44.   18.   45.   51.   24.     nan 41.   21.   48.     nan\n 24.   42.   27.   31.     nan  4.   26.   47.   33.   47.   28.   15.\n 20.   19.     nan 56.   25.   33.   22.   28.   25.   39.   27.   19.\n   nan 26.   32.  ].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-06dbf01971b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mimputer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKNNImputer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mimputer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAge\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/impute/_knn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         X = check_array(X, accept_sparse=False, dtype=FLOAT_DTYPES,\n\u001b[0;32m--> 182\u001b[0;31m                         force_all_finite=force_all_finite, copy=self.copy)\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_indicator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    554\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m                     \u001b[0;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[1;32m    557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;31m# in the future np.flexible dtypes will be handled like object dtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[22.   38.   26.   35.   35.     nan 54.    2.   27.   14.    4.   58.\n 20.   39.   14.   55.    2.     nan 31.     nan 35.   34.   15.   28.\n  8.   38.     nan 19.     nan   nan 40.     nan   nan 66.   28.   42.\n   nan 21.   18.   14.   40.   27.     nan  3.   19.     nan   nan   nan\n   nan 18.    7.   21.   49.   29.   65.     nan 21.   28.5   5.   11.\n 22.   38.   45.    4.     nan   nan 29.   19.   17.   26.   32.   16.\n 21.   26.   32.   25.     nan   nan  0.83 30.   22.   29.     nan 28.\n 17.   33.   16.     nan 23.   24.   29.   20.   46.   26.   59.     nan\n 71.   23.   34.   34.   28.     nan 21.   33.   37.   28.   21.     nan\n 38.     nan 47.   14.5  22.   20.   17.   21.   70.5  29.   24.    2.\n 21.     nan 32.5  32.5  54.   12.     nan 24.     nan 45.   33.   20.\n 47.   29.   25.   23.   19.   37.   16.   24.     nan 22.   24.   19.\n 18.   19.   27.    9.   36.5  42.   51.   22.   55.5  40.5    nan 51.\n 16.   30.     nan   nan 44.   40.   26.   17.    1.    9.     nan 45.\n   nan 28.   61.    4.    1.   21.   56.   18.     nan 50.   30.   36.\n   nan   nan  9.    1.    4.     nan   nan 45.   40.   36.   32.   19.\n 19.    3.   44.   58.     nan 42.     nan 24.   28.     nan 34.   45.5\n 18.    2.   32.   26.   16.   40.   24.   35.   22.   30.     nan 31.\n 27.   42.   32.   30.   16.   27.   51.     nan 38.   22.   19.   20.5\n 18.     nan 35.   29.   59.    5.   24.     nan 44.    8.   19.   33.\n   nan   nan 29.   22.   30.   44.   25.   24.   37.   54.     nan 29.\n 62.   30.   41.   29.     nan 30.   35.   50.     nan  3.   52.   40.\n   nan 36.   16.   25.   58.   35.     nan 25.   41.   37.     nan 63.\n 45.     nan  7.   35.   65.   28.   16.   19.     nan 33.   30.   22.\n 42.   22.   26.   19.   36.   24.   24.     nan 23.5   2.     nan 50.\n   nan   nan 19.     nan   nan  0.92   nan 17.   30.   30.   24.   18.\n 26.   28.   43.   26.   24.   54.   31.   40.   22.   27.   30.   22.\n   nan 36.   61.   36.   31.   16.     nan 45.5  38.   16.     nan   nan\n 29.   41.   45.   45.    2.   24.   28.   25.   36.   24.   40.     nan\n  3.   42.   23.     nan 15.   25.     nan 28.   22.   38.     nan   nan\n 40.   29.   45.   35.     nan 30.   60.     nan   nan 24.   25.   18.\n 19.   22.    3.     nan 22.   27.   20.   19.   42.    1.   32.   35.\n   nan 18.    1.   36.     nan 17.   36.   21.   28.   23.   24.   22.\n 31.   46.   23.   28.   39.   26.   21.   28.   20.   34.   51.    3.\n 21.     nan   nan   nan 33.     nan 44.     nan 34.   18.   30.   10.\n   nan 21.   29.   28.   18.     nan 28.   19.     nan 32.   28.     nan\n 42.   17.   50.   14.   21.   24.   64.   31.   45.   20.   25.   28.\n   nan  4.   13.   34.    5.   52.   36.     nan 30.   49.     nan 29.\n 65.     nan 50.     nan 48.   34.   47.   48.     nan 38.     nan 56.\n   nan  0.75   nan 38.   33.   23.   22.     nan 34.   29.   22.    2.\n  9.     nan 50.   63.   25.     nan 35.   58.   30.    9.     nan 21.\n 55.   71.   21.     nan 54.     nan 25.   24.   17.   21.     nan 37.\n 16.   18.   33.     nan 28.   26.   29.     nan 36.   54.   24.   47.\n 34.     nan 36.   32.   30.   22.     nan 44.     nan 40.5  50.     nan\n 39.   23.    2.     nan 17.     nan 30.    7.   45.   30.     nan 22.\n 36.    9.   11.   32.   50.   64.   19.     nan 33.    8.   17.   27.\n   nan 22.   22.   62.   48.     nan 39.   36.     nan 40.   28.     nan\n   nan 24.   19.   29.     nan 32.   62.   53.   36.     nan 16.   19.\n 34.   39.     nan 32.   25.   39.   54.   36.     nan 18.   47.   60.\n 22.     nan 35.   52.   47.     nan 37.   36.     nan 49.     nan 49.\n 24.     nan   nan 44.   35.   36.   30.   27.   22.   40.   39.     nan\n   nan   nan 35.   24.   34.   26.    4.   26.   27.   42.   20.   21.\n 21.   61.   57.   21.   26.     nan 80.   51.   32.     nan  9.   28.\n 32.   31.   41.     nan 20.   24.    2.     nan  0.75 48.   19.   56.\n   nan 23.     nan 18.   21.     nan 18.   24.     nan 32.   23.   58.\n 50.   40.   47.   36.   20.   32.   25.     nan 43.     nan 40.   31.\n 70.   31.     nan 18.   24.5  18.   43.   36.     nan 27.   20.   14.\n 60.   25.   14.   19.   18.   15.   31.    4.     nan 25.   60.   52.\n 44.     nan 49.   42.   18.   35.   18.   25.   26.   39.   45.   42.\n 22.     nan 24.     nan 48.   29.   52.   19.   38.   27.     nan 33.\n  6.   17.   34.   50.   27.   20.   30.     nan 25.   25.   29.   11.\n   nan 23.   23.   28.5  48.   35.     nan   nan   nan 36.   21.   24.\n 31.   70.   16.   30.   19.   31.    4.    6.   33.   23.   48.    0.67\n 28.   18.   34.   33.     nan 41.   20.   36.   16.   51.     nan 30.5\n   nan 32.   24.   48.   57.     nan 54.   18.     nan  5.     nan 43.\n 13.   17.   29.     nan 25.   25.   18.    8.    1.   46.     nan 16.\n   nan   nan 25.   39.   49.   31.   30.   30.   34.   31.   11.    0.42\n 27.   31.   39.   18.   39.   33.   26.   39.   35.    6.   30.5    nan\n 23.   31.   43.   10.   52.   27.   38.   27.    2.     nan   nan  1.\n   nan 62.   15.    0.83   nan 23.   18.   39.   21.     nan 32.     nan\n 20.   16.   30.   34.5  17.   42.     nan 35.   28.     nan  4.   74.\n  9.   16.   44.   18.   45.   51.   24.     nan 41.   21.   48.     nan\n 24.   42.   27.   31.     nan  4.   26.   47.   33.   47.   28.   15.\n 20.   19.     nan 56.   25.   33.   22.   28.   25.   39.   27.   19.\n   nan 26.   32.  ].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "from sklearn.impute import KNNImputer \n",
    "\n",
    "imputer = KNNImputer(n_neighbors=2)\n",
    "imputer.fit_transform(train.Age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost's prediction accuracy is: 81.02\n",
      "Time consumed for training: 0.055\n",
      "Time consumed for prediction: 0.00209 seconds\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(n_estimators=100)\n",
    "training_start = time.perf_counter()\n",
    "xgb.fit(X_train, y_train)\n",
    "training_end = time.perf_counter()\n",
    "prediction_start = time.perf_counter()\n",
    "preds = xgb.predict(X_test)\n",
    "prediction_end = time.perf_counter()\n",
    "acc_xgb = (preds == y_test).sum().astype(float) / len(preds)*100\n",
    "xgb_train_time = training_end-training_start\n",
    "xgb_prediction_time = prediction_end-prediction_start\n",
    "print(\"XGBoost's prediction accuracy is: %3.2f\" % (acc_xgb))\n",
    "print(\"Time consumed for training: %4.3f\" % (xgb_train_time))\n",
    "print(\"Time consumed for prediction: %6.5f seconds\" % (xgb_prediction_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-218f4a603f35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mrfc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtraining_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mrfc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtraining_end\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprediction_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \"\"\"\n\u001b[1;32m    294\u001b[0m         \u001b[0;31m# Validate or convert input data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    576\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m             _assert_all_finite(array,\n\u001b[0;32m--> 578\u001b[0;31m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[1;32m    579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m     58\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                     (type_err,\n\u001b[0;32m---> 60\u001b[0;31m                      msg_dtype if msg_dtype is not None else X.dtype)\n\u001b[0m\u001b[1;32m     61\u001b[0m             )\n\u001b[1;32m     62\u001b[0m     \u001b[0;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=10)\n",
    "training_start = time.perf_counter()\n",
    "rfc.fit(X_train, y_train)\n",
    "training_end = time.perf_counter()\n",
    "prediction_start = time.perf_counter()\n",
    "preds = rfc.predict(X_test)\n",
    "prediction_end = time.perf_counter()\n",
    "acc_rfc = (preds == y_test).sum().astype(float) / len(preds)*100\n",
    "rfc_train_time = training_end-training_start\n",
    "rfc_prediction_time = prediction_end-prediction_start\n",
    "print(\"Scikit-Learn's Random Forest Classifier's prediction accuracy is: %3.2f\" % (acc_rfc))\n",
    "print(\"Time consumed for training: %4.3f seconds\" % (rfc_train_time))\n",
    "print(\"Time consumed for prediction: %6.5f seconds\" % (rfc_prediction_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
